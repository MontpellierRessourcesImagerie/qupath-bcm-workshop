{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3649c793",
   "metadata": {},
   "source": [
    "| [![back](../../media/navigation/back.png)](../../exercises/tissue-classification-segmentation/ex4.html) | [![home](../../media/navigation/home.png)](../../index.html) | [![next](../../media/navigation/next.png)](../../exercises/tissue-classification-segmentation/ex6.html) |\n",
    "| :---: | :---: | :---: |\n",
    "| Ex 4.4: Semi-automatic segmentation using SAM | â€¢ | Ex 4.6: Area of signal per slide |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c721d8",
   "metadata": {},
   "source": [
    "# 4. Tissue segmentation and classification\n",
    "\n",
    "## 4.5 Segmentation quality control\n",
    "\n",
    "Are you happy with the segmentation that you made at the previous exercise? Or at the opposite, do you think that it is quite terrible? These descriptions sound very arbitrary and depend on who is talking. So far, we simply made a visual assessment of the quality of our segmentation, but we didn't quantify how good or bad it is. If we needed to rank all the classifiers that we made to know who has the most precise one, we would need numeric values describing the output of our classifiers.\n",
    "\n",
    "### 4.5.1 Xxxxxxx xxxxxx xxxxxx"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
