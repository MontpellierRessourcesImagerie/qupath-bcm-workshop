{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37f15b0",
   "metadata": {},
   "source": [
    "| [![back](../../media/navigation/back.png)](../../exercises/tissue-classification-segmentation/ex3.html) | [![home](../../media/navigation/home.png)](../../index.html) |\n",
    "| :---: | :---: |\n",
    "| Ex 4.3: Using a N-classes pixel classifier | â€¢ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5bb7ec",
   "metadata": {},
   "source": [
    "# 4. Tissue segmentation and classification\n",
    "\n",
    "## 4.4 Semi-automatic segmentation using SAM\n",
    "\n",
    "SAM (Segment Anything Model) is a deep-learning architecture created by Meta (Facebook, Instagram, ...). It allows, given a bounding-box user input, to segment the object theoritically present in that box.\n",
    "\n",
    "### 4.4.1 Glomerulus-to-kidney ratio\n",
    "\n",
    "#### Goals:\n",
    "\n",
    "We will try to achieve the same task in this exercise as in the [Ex1: Fully manual tissue segmentation](../../exercises/tissue-classification-segmentation/ex1.ipynb) but we will use it doing deep-learning rather than manual annotations.\n",
    "\n",
    "#### Required data:\n",
    "\n",
    "| **Folder** | Description | Location | License |\n",
    "| --- | --- | --- | --- |\n",
    "| Histology (PAS-HE-IHC) | H-DAB images of kidneys into which glomerulus are visible and lungs into which alveolus are present | [DOI: 10.1038/s41467-023-40291-0](https://www.kaggle.com/datasets/yashvrdnjain/histology-pas-he-ihc-images-ftu-segmentation) | MIT |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
