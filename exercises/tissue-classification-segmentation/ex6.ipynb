{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c09354f",
   "metadata": {},
   "source": [
    "| [![back](../../media/navigation/back.png)](../../exercises/tissue-classification-segmentation/ex5.html) | [![home](../../media/navigation/home.png)](../../index.html) |\n",
    "| :---: | :---: |\n",
    "| Ex 4.5: Segmentation quality control | â€¢ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61829b7e",
   "metadata": {},
   "source": [
    "# 4. Tissue segmentation and classification\n",
    "\n",
    "## 4.6 Area of signal per slide\n",
    "\n",
    "Measuring the area taken by the signal of N channels in a fluo image is a quite common task but several pitfalls must be avoided, the main one being to adjust the brightness and contrast for each image.\n",
    "\n",
    "### 4.6.1 Area of P1, P2 and P3 per slide\n",
    "\n",
    "#### Goals:\n",
    "\n",
    "We want to measure the area covered by the signal on each channel, on the whole images, following several rules. The rules are the following one:\n",
    "- The channel 1 and 2 are mutually exclusive (== there cannot be 1 where there is 2 and vice versa)\n",
    "- The channel 3 is mutually exclusive with 1 and 2 (== if there is 1 or 2, you can't have 3)\n",
    "To satisfy these constraints, we will train a pixel classifier (like for [Ex 4.3: Using a N-classes pixel classifier](../../exercises/tissue-classification-segmentation/ex3.html)) on training image containing representative regions.\n",
    "\n",
    "We will try to find 4 classes: `P1`, `P2`, `P3` and `Ignore*`.\n",
    "\n",
    "#### Required data:\n",
    "\n",
    "| **Folder** | Description | Location | License |\n",
    "| --- | --- | --- | --- |\n",
    "| Area of fluo | Fluo images with three channels containing objects that we will name P1, P2 and P3 | Courtesy of Claire CRAMPES and Tommy CHASTEL, Andrei TURTOI team, IRCM | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca865f",
   "metadata": {},
   "source": [
    "### A. Create a training image\n",
    "\n",
    "- On these images, the whole field contains something, so we can skip the step where we segment the whole organ. We can pass to the training right away. The first step is to create a training image containing representative areas on the slide.\n",
    "- To help you pick your regions, you should visualize your images using the same LUT and brightness and contrast.\n",
    "- To do that, we will start by using the script that you can find in [scripts/utils/ch_name_and_luts.groovy](../../scripts/utils/ch_name_and_luts.groovy). If you load it in QuPath, you can edit the content of `channels_name` to set the channel names to `P1`, `P2` and `P3`. You must also change the content of `LUTs` so the names match the channel names that we just provided. If you whish, you can change the LUTs by providing some RGB triplets as you can find using [any color picker](https://htmlcolorcodes.com/color-picker/).\n",
    "- Once you chose your names and your LUT, run the script **for the whole project**.\n",
    "- You can now open the ![QP channels tools](../../media/qp-icons/channels-tol.png) channels tools, but before adjusting anything, make sure that the \"Apply to similar images\" checkbox (at the very bottom of the floating window) is activated. That will apply the same B&C to all the images of your project.\n",
    "- Using some ![QP rect ann](../../media/qp-icons/rectangle-selection.png) rectangle annotations and the `Region*` class, you can now constitute a representative set of regions.\n",
    "- Once you estimate that your set contains approximately every situation, you can go to the top bar menu and create your training image using \"Classify\" > \"Training images\" > \"Create training image...\". If you used the `Region*` class for your rectangles, you don't have anything to change in the settings.\n",
    "\n",
    "![train img fluo](../../media/tissue-classification/training-fluo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc354c",
   "metadata": {},
   "source": [
    "### B. Train the classifier\n",
    "\n",
    "- We named our channels `P1`, `P2` and `P3` but it is very unlikely that you have the classes `P1`, `P2` and `P3` in your class list.\n",
    "- To address this situation, you can go to the top of your class list, next to the \"+\" and \"-\" button you should have a little triangular button. If you click on it, you should see the option \"Populate from image channels\". If you launch it, the list should now contain the classes that we need.\n",
    "- Activate the ![QP point cloud](../../media/qp-icons/points-selection.png) point clouds tool and using the \"Add\" button, create 4 point clouds. Give the classes `P1`, `P2` and `P3` to three of them, and `Ignore*` to the last one (that will contain the background).\n",
    "- Like we did at the [Ex 4.3: Using a N-classes pixel classifier](../../exercises/tissue-classification-segmentation/ex3.html), start by providing betwen 10 and 20 points per class using the rules mentionned in the \"Goals\" section of this exrcise.\n",
    "- Then, go to \"Classify\" > \"Pixel classification\" > \"Train pixel classifier...\"\n",
    "- Start by choosing the algorithm (Random trees) and adjusting the resolution. If you look at the images, you will notice that the signal of P2 makes small spots of a few pixels of radius in certain situations, so we need to work at full resolution.\n",
    "- With the \"Live prediction\" ativated, you should now choose your features and their radii by checking whether they are useful or not.\n",
    "- Eventually, you will add points until the result looks satisfying, give a name to your classifier and save it."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
